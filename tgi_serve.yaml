name: vllm-text-generation-interface
message: Quickstart to serve Llama 3 model with a TGI.
image: ghcr.io/huggingface/text-generation-inference:2.0.2
resources:
  cluster: snu-eng-dgx
  preset: a100-2
run:
- command: echo "Hello, TGI!"
  workdir: /root
- command: |
    text-generation-launcher \
      --hostname 0.0.0.0 \
      --model-id $MODEL_ID \
      --port 8000 \
      --max-total-tokens 8192
  workdir: /code
ports:
- name: default
  type: http
  port: 8000
env:
  MODEL_ID: casperhansen/llama-3-8b-instruct-awq
service:
  autoscaling:
    max: 2
    metric: cpu
    min: 1
    target: 50
  expose: 8000